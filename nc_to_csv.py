import os
import pandas as pd
import numpy as np
import json
from netCDF4 import Dataset
from astropy.time import Time
import warnings
from datetime import datetime, timedelta

warnings.filterwarnings(action='ignore')

# ì‹¤í–‰ ê²½ë¡œ ì„¤ì •
script_path = os.path.abspath(__file__)
script_directory = os.path.dirname(script_path)
base_path = os.path.dirname(script_directory)

nc_data_path = os.path.join(base_path, "ENSEMBLE_MODEL_CROP_DATA")
save_path = os.path.join(base_path, "ENSEMBLE_MODEL_STATION_DATA")
os.makedirs(save_path, exist_ok=True)


# JSON íŒŒì¼ì—ì„œ target_lat, target_lon, target_date ë¶ˆëŸ¬ì˜¤ê¸°
json_path = os.path.join(base_path, "target_metadata.json")
if not os.path.exists(json_path):
    raise FileNotFoundError(f"JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path}")

with open(json_path, 'r', encoding='utf-8') as f:
    target_metadata = json.load(f)

target_lat = target_metadata['target_lat']
target_lon = target_metadata['target_lon']
target_date = target_metadata['target_date']

print(f"JSONì—ì„œ target ì •ë³´ ë¡œë“œë¨: ìœ„ë„ {target_lat}, ê²½ë„ {target_lon}, ë‚ ì§œ {target_date}")


# ê°€ì¥ ê°€ê¹Œìš´ ê´€ì¸¡ì†Œ ì°¾ê¸° (SAR_meta_data.csv í™œìš©)
meta_data_path = os.path.join(base_path, "SAR_meta_data.csv")
if not os.path.exists(meta_data_path):
    raise FileNotFoundError(f"ê´€ì¸¡ì†Œ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {meta_data_path}")

meta_df = pd.read_csv(meta_data_path, encoding='cp949')

# í•˜ë²„ì‚¬ì¸ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜
def haversine(lat1, lon1, lat2, lon2):
    R = 6371.0  # ì§€êµ¬ ë°˜ì§€ë¦„ (km)
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2
    c = 2 * np.arcsin(np.sqrt(a))
    return R * c

# target_lat, target_lonê³¼ ëª¨ë“  ê´€ì¸¡ì†Œì˜ ê±°ë¦¬ ê³„ì‚°
meta_df['distance'] = meta_df.apply(lambda row: haversine(target_lat, target_lon, row['lat'], row['lon']), axis=1)

# ê°€ì¥ ê°€ê¹Œìš´ ê´€ì¸¡ì†Œ ì„ íƒ
nearest_station = meta_df.loc[meta_df['distance'].idxmin()]
station_num = nearest_station['stn_num']
station_name = nearest_station['stn_na']

print(f"ê°€ì¥ ê°€ê¹Œìš´ ê´€ì¸¡ì†Œ: {station_num} ({station_name})")

# target_metadata.jsonì— ê°€ì¥ ê°€ê¹Œìš´ ê´€ì¸¡ì†Œ ë²ˆí˜¸ ì¶”ê°€
with open(json_path, 'w', encoding='utf-8') as f:
    json.dump(target_metadata, f, indent=4)

target_metadata['station_num'] = station_num
target_metadata['station_name'] = station_name
with open(json_path, 'w', encoding='utf-8') as f:
    json.dump(target_metadata, f, indent=4)

print(f"target_metadata.jsonì— station ì •ë³´ ì¶”ê°€ë¨: {station_name} ({station_num})")

# target_dateë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜
target_datetime = datetime.strptime(target_date, "%Y%m%d%H")

# 10ì¼ì¹˜ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸ ìƒì„± (12ì‹œê°„ ê°„ê²© í¬í•¨)
date_list = [(target_datetime - timedelta(hours=12 * i)).strftime("%Y%m%d%H") for i in range(21)]  # 10ì¼ì¹˜ 12ì‹œê°„ ê°„ê²©

print(f"10ì¼ì¹˜(12ì‹œê°„ ê°„ê²©) nc íŒŒì¼ì„ ì²˜ë¦¬í•  ë‚ ì§œ ëª©ë¡: {date_list}")



# ê° ë‚ ì§œë³„ NetCDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ CSVë¡œ ì €ì¥
for date in date_list:
    nc_file = os.path.join(nc_data_path, f"cropped_{date}.nc")
    if not os.path.exists(nc_file):
        print(f"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {nc_file}. ê±´ë„ˆëœë‹ˆë‹¤.")
        continue

    print(f"ğŸ“‚ {nc_file} ì²˜ë¦¬ ì¤‘...")
    nc = Dataset(nc_file)

    # NetCDF íŒŒì¼ì—ì„œ ìœ„ë„, ê²½ë„, ì‹œê°„ ë°ì´í„° ë¡œë“œ
    lats = nc.variables['latitude'][:]
    lons = nc.variables['longitude'][:]
    time_data = nc.variables['time'][:]

    valid_points = 0

    # 300km ë°˜ê²½ ë‚´ ëª¨ë“  ìœ„ë„-ê²½ë„ ì¡°í•©ë³„ë¡œ ì²˜ë¦¬
    for lat in lats:
        for lon in lons:
            if haversine(target_lat, target_lon, lat, lon) <= 300:  
                valid_points += 1
                lat_idx = np.abs(lats - lat).argmin()
                lon_idx = np.abs(lons - lon).argmin()
                print(f"  ğŸ“ ì €ì¥í•  ì§€ì : ìœ„ë„ {lat:.2f}, ê²½ë„ {lon:.2f} (Index: LAT {lat_idx}, LON {lon_idx})")

                # ì‹œê°„ ë°ì´í„°ë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
                t_vec = Time(time_data, format='unix', scale='utc')
                t_vec_2 = t_vec.datetime  # datetime ë¦¬ìŠ¤íŠ¸

                # DataFrame ìƒì„± 
                df = pd.DataFrame({'TIME': t_vec_2})

                for var_name, var_data in nc.variables.items():
                    if var_name not in ['latitude', 'longitude', 'time']:
                        if 'time' in var_data.dimensions:
                            df[var_name] = var_data[:, lat_idx, lon_idx]

                # ì¶”ê°€ ì •ë³´ ê¸°ì…
                df['STN_NO'] = station_num
                df['LAT'] = lat
                df['LON'] = lon        
                df['LAT_I'] = lat_idx
                df['LON_J'] = lon_idx

                # CSV ì €ì¥ (íŒŒì¼ëª…: {station_name}_{station_num}_{lat}_{lon}_{date}.csv)
                csv_file = os.path.join(save_path, f"{station_num}_{lat:.2f}_{lon:.2f}_{date}.csv")
                df.to_csv(csv_file, encoding='utf-8-sig', index=False)
                print(f"ì €ì¥ ì™„ë£Œ: {csv_file}")

    nc.close()
print(f"300km ë°˜ê²½ ë‚´ (lat, lon) ì¡°í•© ê°œìˆ˜: {valid_points}")
print("10ì¼ì¹˜(12ì‹œê°„ ê°„ê²©) NetCDF â†’ CSV ë³€í™˜ ì™„ë£Œ")